{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e823aed",
      "metadata": {
        "id": "1e823aed"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fab15eb1",
      "metadata": {
        "id": "fab15eb1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets.utils import download_url\n",
        "import os\n",
        "#import cv2\n",
        "import math\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import FileLink\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fbfda156",
      "metadata": {
        "id": "fbfda156"
      },
      "outputs": [],
      "source": [
        "def relu(_input):\n",
        "    model = nn.ReLU()\n",
        "    return model(_input)\n",
        "\n",
        "def lrelu(_input):\n",
        "    model = nn.LeakyReLU(0.2)\n",
        "    return model(_input)\n",
        "\n",
        "def batch_norm():\n",
        "    pass\n",
        "\n",
        "def conv_2d(_input, ni, nf, ks, stride=2):\n",
        "    model = nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
        "    return model(_input)\n",
        "\n",
        "def conv_bn(_input, ni, nf, ks, stride):\n",
        "    #out1 = conv_2d(_input, ni, nf, ks, stride)\n",
        "    #model2 = nn.BatchNorm2d(nf)\n",
        "    #return model2(out1)\n",
        "    model = nn.Sequential(nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2), \n",
        "                          nn.BatchNorm2d(nf)\n",
        "                         )\n",
        "    return model(_input)\n",
        "\n",
        "def conv_bn_lrelu(_input, ni, nf, ks, stride):\n",
        "    out1 = conv_bn(_input, ni, nf, ks, stride)\n",
        "    out2 = lrelu(out1)\n",
        "    return out2\n",
        "\n",
        "def conv_tanh(_input, ni, nf=3, ks=3, stride=1):\n",
        "    model = nn.Sequential(nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2), \n",
        "                          nn.Tanh()\n",
        "                         )\n",
        "    return model(_input)\n",
        "    \n",
        "def fc_nn(_input, input_size, output_size):\n",
        "    model = nn.Sequential(nn.Flatten(), \n",
        "                          nn.Linear(input_size, output_size)\n",
        "                         )\n",
        "    return model(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5b48891b",
      "metadata": {
        "id": "5b48891b"
      },
      "outputs": [],
      "source": [
        "def res_block(_input, ni, ks=3, stride=1):\n",
        "    out1 = conv_bn_lrelu(_input, ni, ni, ks, stride)\n",
        "    out2 = conv_bn(out1, ni, ni, ks, stride)\n",
        "    out3 = _input + out2\n",
        "    out4 = lrelu(out3)\n",
        "    return out4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "28f9222f",
      "metadata": {
        "id": "28f9222f"
      },
      "outputs": [],
      "source": [
        "def generator_global_encoder(_input):\n",
        "    ni = 3\n",
        "    nf = 64\n",
        "    \n",
        "    conv0_ = conv_2d(_input, ni, nf, ks=7, stride=1)\n",
        "    conv0 = lrelu(conv0_)\n",
        "    conv0r = res_block(conv0, nf, ks=7)\n",
        "    \n",
        "    conv1 = conv_bn_lrelu(conv0r, nf*1, nf*1, ks=5, stride=2)\n",
        "    conv1r = res_block(conv1, nf*1, ks=5)\n",
        "    \n",
        "    conv2 = conv_bn_lrelu(conv1r, nf*1, nf*2, ks=3, stride=2)\n",
        "    conv2r = res_block(conv2, nf*2, ks=3)\n",
        "    \n",
        "    conv3 = conv_bn_lrelu(conv2r, nf*2, nf*4, ks=3, stride=2)\n",
        "    conv3r = res_block(conv3, nf*4, ks=3)\n",
        "    \n",
        "    conv4 = conv_bn_lrelu(conv3r, nf*4, nf*8, ks=3, stride=2)\n",
        "    conv4r1 = res_block(conv4, nf*8, ks=3)\n",
        "    conv4r2 = res_block(conv4r1, nf*8, ks=3)\n",
        "    conv4r3 = res_block(conv4r2, nf*8, ks=3)\n",
        "    conv4r4 = res_block(conv4r3, nf*8, ks=3)\n",
        "    \n",
        "    fc1 = fc_nn(conv4r4, 64*512, 512)\n",
        "    fc2 = torch.maximum(fc1[:, 0:256], fc1[:, 256:])\n",
        "    \n",
        "    return conv0r, conv1r, conv2r, conv3r, conv4r4, fc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7da631eb",
      "metadata": {
        "id": "7da631eb"
      },
      "outputs": [],
      "source": [
        "def deconv_2d(_input, ni, nf, ks, stride=2, padding=1, output_padding=1):\n",
        "    model = nn.ConvTranspose2d(in_channels=ni, out_channels=nf, \n",
        "                               kernel_size=ks, stride=stride, \n",
        "                               padding=padding, output_padding=output_padding)\n",
        "    return model(_input)\n",
        "\n",
        "def deconv_bn_relu(_input, ni, nf, ks, stride=2, padding=1, output_padding=1):\n",
        "    model = nn.Sequential(nn.ConvTranspose2d(in_channels=ni, out_channels=nf, \n",
        "                               kernel_size=ks, stride=stride, \n",
        "                               padding=padding, output_padding=output_padding),\n",
        "                          nn.BatchNorm2d(nf),\n",
        "                          nn.ReLU())\n",
        "    return model(_input)\n",
        "\n",
        "def deconv_bn_lrelu(_input, ni, nf, ks, stride=2, padding=1, output_padding=1):\n",
        "    model = nn.Sequential(nn.ConvTranspose2d(in_channels=ni, out_channels=nf, \n",
        "                               kernel_size=ks, stride=stride, \n",
        "                               padding=padding, output_padding=output_padding),\n",
        "                          nn.BatchNorm2d(nf), \n",
        "                          nn.LeakyReLU(0.2))\n",
        "    return model(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d8a6c47c",
      "metadata": {
        "id": "d8a6c47c"
      },
      "outputs": [],
      "source": [
        "#Implementation\n",
        "def generator_global_decoder(conv0, conv1, conv2, conv3, conv4, fc):\n",
        "    \n",
        "    batch_size = fc.shape[0]\n",
        "    \n",
        "    I_P_32 = torch.randn(batch_size, 32, 32, 32)\n",
        "    I_P_64 = torch.randn(batch_size, 32, 64, 64)\n",
        "    I_P_128 = torch.randn(batch_size, 32, 128, 128)\n",
        "    \n",
        "    #Layer-feat8\n",
        "    noise = torch.randn(batch_size, 256)\n",
        "    _input = torch.cat((fc, noise), 1)  #Output: [bs, 512]\n",
        "    feat8 = relu(fc_nn(_input, 512, 64*8*8).reshape([batch_size, 64, 8, 8])) #Output: [bs, 64, 8, 8]\n",
        "    \n",
        "    \n",
        "    #Layer-feat32\n",
        "    feat32 = relu(deconv_2d(feat8, 64, 32, 3, 4, 0, 1))  #Output: [bs, 32, 32, 32]\n",
        "    \n",
        "    \n",
        "    #Layer-feat64\n",
        "    feat64 = relu(deconv_2d(feat32, 32, 16, 3, 2, 1, 1)) #Output: [bs, 16, 64, 64]\n",
        "\n",
        "    \n",
        "    #Layer-feat128\n",
        "    feat128 = relu(deconv_2d(feat64, 16, 8, 3, 2, 1, 1)) #Output: [bs, 8, 128, 128]\n",
        "\n",
        "    \n",
        "    #Layer - deconv0\n",
        "    select8_res_1_t = torch.cat((feat8, conv4), 1) #Output: [bs, 576, 8, 8]\n",
        "    select8_res_1 = res_block(select8_res_1_t, ni=576, ks=3) #Output: [bs, 576, 8, 8]\n",
        "    dec8_res2 = res_block(res_block(select8_res_1, ni=576, ks=3), ni=576, ks=3) #Output: [bs, 576, 8, 8]\n",
        "    deconv0_16 = deconv_bn_relu(dec8_res2, 576, 512, 3, 2, 1, 1) #Output: [bs, 512, 16, 16]\n",
        "    \n",
        "    \n",
        "    #Layer - deconv1\n",
        "    select16_res_1 = res_block(conv3, ni=256) #Output: [bs, 256, 16, 16]\n",
        "    dec16_res2_t = torch.cat((deconv0_16, select16_res_1), 1) #Output: [bs, 768, 16, 16]\n",
        "    dec16_res2 = res_block(res_block(dec16_res2_t, ni=768, ks=3), ni=768, ks=3) #Output: [bs, 768, 16, 16]\n",
        "    deconv1_32 = deconv_bn_relu(dec16_res2, 768, 256, 3, 2, 1, 1) #Output: [bs, 256, 32, 32]\n",
        "    \n",
        "    \n",
        "    #Layer - deconv2\n",
        "    select32_res_1_t = torch.cat((conv2, feat32, I_P_32), 1) #Output: [bs, 192, 32, 32]\n",
        "    select32_res_1 = res_block(select32_res_1_t, ni=192, ks=3) #Output: [bs, 192, 32, 32]\n",
        "    dec32_res2_t = torch.cat((deconv1_32, select32_res_1), 1) #Output: [bs, 448, 32, 32]\n",
        "    dec32_res2 = res_block(res_block(dec32_res2_t, ni=448, ks=3), ni=448, ks=3) #Output: [bs, 448, 32, 32]\n",
        "    deconv2_64 = deconv_bn_relu(dec32_res2, 448, 128, 3, 2, 1, 1) #Output: [bs, 128, 64, 64]\n",
        "    \n",
        "    img32 = conv_tanh(dec32_res2, ni=448, nf=3, ks=3) #Output: [bs, 3, 32, 32]\n",
        "    \n",
        "    \n",
        "    #Layer - deconv3\n",
        "    select64_res_1_t = torch.cat((conv1, feat64, I_P_64), 1) #Output: [bs, 112, 64, 64]\n",
        "    select64_res_1 = res_block(select64_res_1_t, ni=112, ks=5) #Output: [bs, 112, 64, 64]\n",
        "    dec64_res2_t = torch.cat((deconv2_64, select64_res_1), 1) #Output: [bs, 240, 64, 64] \n",
        "    #Not concatenated img32\n",
        "    dec64_res2 = res_block(res_block(dec64_res2_t, ni=240, ks=3), ni=240, ks=3) #Output: [bs, 240, 64, 64] \n",
        "    deconv3_128 = deconv_bn_relu(dec64_res2, 240, 64, 3, 2, 1, 1) #Output: [bs, 64, 128, 128]\n",
        "    \n",
        "    img64 = conv_tanh(dec64_res2, ni=240, nf=3, ks=3) #Output: [bs, 3, 64, 64]\n",
        "    \n",
        "    \n",
        "    #Layer - conv5\n",
        "    select128_res_1_t = torch.cat((conv0, feat128, I_P_128), 1) #Output: [bs, 104, 128, 128]\n",
        "    select128_res_1 = res_block(select128_res_1_t, ni=104, ks=7) #Output: [bs, 104, 128, 128]\n",
        "    dec128_res2_t = torch.cat((deconv3_128, select128_res_1), 1) #Output: [bs, 168, 128, 128] \n",
        "    #Not concatenated img64, eyel, eyer, nose, mouth, c_eyel, c_eyer, c_nose, c_mouth\n",
        "    dec128_res2 = res_block(dec128_res2_t, ni=168, ks=5) #Output: [bs, 168, 128, 128]\n",
        "    dec128_conv5 = conv_bn_lrelu(dec128_res2, ni=168, nf=64, ks=5, stride=1) #Output: [bs, 64, 128, 128]\n",
        "    dec128_conv5_r = res_block(dec128_conv5, ni=64) #Output: [bs, 64, 128, 128]\n",
        "    \n",
        "    \n",
        "    #Layer - conv6\n",
        "    dec128_conv6 = conv_bn_lrelu(dec128_conv5_r, ni=64, nf=32, ks=3, stride=1) #Output: [bs, 32, 128, 128]\n",
        "    \n",
        "    \n",
        "    #Layer - conv7\n",
        "    img128 = conv_tanh(dec128_conv6, ni=32, nf=3) #Output: [bs, 3, 128, 128]\n",
        "    \n",
        "    return img128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c78d53",
      "metadata": {
        "id": "10c78d53"
      },
      "outputs": [],
      "source": [
        "conv0 = torch.randn(49, 64, 128, 128)\n",
        "conv1 = torch.randn(49, 64, 64, 64)\n",
        "conv2 = torch.randn(49, 128, 32, 32)\n",
        "conv3 = torch.randn(49, 256, 16, 16)\n",
        "conv4 = torch.randn(49, 512, 8, 8)\n",
        "fc = torch.randn(49, 256)\n",
        "\n",
        "output = generator_global_decoder(conv0, conv1, conv2, conv3, conv4, fc)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f5e88e",
      "metadata": {
        "id": "79f5e88e"
      },
      "outputs": [],
      "source": [
        "input1 = torch.randn(49, 3, 128, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "266fbfed",
      "metadata": {
        "id": "266fbfed"
      },
      "outputs": [],
      "source": [
        "feats = generator_global_encoder(input1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a600516",
      "metadata": {
        "id": "6a600516"
      },
      "outputs": [],
      "source": [
        "def receive(a1, a2, a3, a4, a5, a6):\n",
        "    print(a1.shape)\n",
        "    print(a2.shape)\n",
        "    print(a3.shape)\n",
        "    print(a4.shape)\n",
        "    print(a5.shape)\n",
        "    print(a6.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e067350d",
      "metadata": {
        "id": "e067350d"
      },
      "outputs": [],
      "source": [
        "receive(*feats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ed099a8",
      "metadata": {
        "id": "3ed099a8"
      },
      "outputs": [],
      "source": [
        "feats[5].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9af7c8",
      "metadata": {
        "id": "1f9af7c8"
      },
      "outputs": [],
      "source": [
        "result = generator_global_encoder(input1)\n",
        "len(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e16761b",
      "metadata": {
        "id": "7e16761b"
      },
      "outputs": [],
      "source": [
        "result[5][:, 0:256].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a71ae08",
      "metadata": {
        "id": "2a71ae08"
      },
      "source": [
        "## Please ignore the code after this point. It was used to test the running of the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a6a31d",
      "metadata": {
        "id": "35a6a31d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff4625d9",
      "metadata": {
        "id": "ff4625d9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f8e1035",
      "metadata": {
        "id": "9f8e1035"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e94304ab",
      "metadata": {
        "id": "e94304ab"
      },
      "source": [
        "### 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b0f6f4",
      "metadata": {
        "id": "a9b0f6f4",
        "outputId": "76287a56-ccb3-4705-8c89-8b59236afd81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([49, 128, 32, 32])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = res_block(conv2, 128)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84447734",
      "metadata": {
        "id": "84447734"
      },
      "source": [
        "### 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6203a163",
      "metadata": {
        "id": "6203a163",
        "outputId": "2d3436f3-d79f-4935-bec1-c7576cfa81f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([104, 64, 8, 8])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input1 = torch.randn(48, 64, 8, 8)\n",
        "input2 = torch.randn(56, 64, 8, 8)\n",
        "\n",
        "a = torch.cat((input1, input2), 0)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8519f215",
      "metadata": {
        "id": "8519f215"
      },
      "source": [
        "### 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aae1c9d",
      "metadata": {
        "id": "9aae1c9d",
        "outputId": "8e41c657-f4cd-4b0a-dab2-e6c56836362c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([49, 5, 1])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aa = 49\n",
        "a = torch.randn(aa, 5, 1)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709c4dd5",
      "metadata": {
        "id": "709c4dd5"
      },
      "source": [
        "### 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d8fe98",
      "metadata": {
        "id": "43d8fe98"
      },
      "outputs": [],
      "source": [
        "m = nn.LeakyReLU(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56a4c74",
      "metadata": {
        "id": "f56a4c74",
        "outputId": "c21ebd2c-14fc-49ec-f3e4-0df985f33496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LeakyReLU(negative_slope=0.1)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c5d38d",
      "metadata": {
        "id": "80c5d38d"
      },
      "outputs": [],
      "source": [
        "input1 = torch.randn(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9745b592",
      "metadata": {
        "id": "9745b592",
        "outputId": "58b3513e-e846-41dd-e107-8f7b1ae76b1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.9483, -1.0663])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfd77c34",
      "metadata": {
        "id": "bfd77c34"
      },
      "outputs": [],
      "source": [
        "output = m(input1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "283a239e",
      "metadata": {
        "id": "283a239e",
        "outputId": "9d814dfe-2579-4fd5-d6d9-da5e7a83b30c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0948, -0.1066])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5efd615c",
      "metadata": {
        "id": "5efd615c"
      },
      "source": [
        "### 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa2f6300",
      "metadata": {
        "id": "aa2f6300"
      },
      "outputs": [],
      "source": [
        "m = nn.Conv2d(16, 33, 3, 2, 1)\n",
        "input2 = torch.randn(20, 16, 600, 50)\n",
        "output = m(input2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "674297d8",
      "metadata": {
        "id": "674297d8",
        "outputId": "80ad229d-1989-4288-c91c-430f215806a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 16, 600, 50])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5416f982",
      "metadata": {
        "id": "5416f982",
        "outputId": "f8c07f82-395d-4049-d6c2-968820e17a48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 300, 25])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39165e6",
      "metadata": {
        "id": "b39165e6",
        "outputId": "f05268ba-1108-4cc0-aaa7-78bd5ddf45d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838beab1",
      "metadata": {
        "id": "838beab1"
      },
      "source": [
        "### 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cfd0fdb",
      "metadata": {
        "id": "5cfd0fdb",
        "outputId": "ccf3cb0d-b5de-4d50-afca-cc1636865474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 300, 25])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input2 = torch.randn(20, 16, 600, 50)\n",
        "a = conv_2d(input2, 16, 33, 3)\n",
        "a.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e00331f",
      "metadata": {
        "id": "9e00331f"
      },
      "source": [
        "### 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b09dc4f",
      "metadata": {
        "id": "4b09dc4f"
      },
      "outputs": [],
      "source": [
        "b = conv_bn_lrelu(input2, 16, 33, 3, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce5e9449",
      "metadata": {
        "id": "ce5e9449",
        "outputId": "2f415e96-0710-48e0-d35c-a99c216e4552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 300, 25])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be30639e",
      "metadata": {
        "id": "be30639e"
      },
      "outputs": [],
      "source": [
        "def generator_global_decoder(feat128, feat64, feat32, feat16, feat8, featvec):\n",
        "    \n",
        "    batch_size = featvec.shape[0]\n",
        "    noise = torch.randn(batch_size, 256)\n",
        "    _input = torch.cat((featvec, noise), 1)  #Output: [bs, 512]\n",
        "    \n",
        "    I_P_32 = torch.randn(batch_size, 32, 32, 32)\n",
        "    I_P_64 = torch.randn(batch_size, 32, 64, 64)\n",
        "    I_P_128 = torch.randn(batch_size, 32, 128, 128)\n",
        "    \n",
        "    initial_8 = relu(fc_nn(_input, 512, 64*8*8).reshape([batch_size, 64, 8, 8])) #Output: [bs, 64, 8, 8]\n",
        "    initial_32 = relu(deconv_2d(initial_8, 64, 32, 3, 4, 0, 1))  #Output: [bs, 32, 32, 32]\n",
        "    initial_64 = relu(deconv_2d(initial_32, 32, 16, 3, 2, 1, 1)) #Output: [bs, 16, 64, 64]\n",
        "    initial_128 = relu(deconv_2d(initial_64, 16, 8, 3, 2, 1, 1)) #Output: [bs, 8, 128, 128]\n",
        "    \n",
        "    before_select8_t = torch.cat((initial_8, feat8), 1) #Output: [bs, 576, 8, 8]\n",
        "    before_select8 = res_block(before_select8_t, ni=576, ks=3) #Output: [bs, 576, 8, 8]\n",
        "    reconstruct8 = res_block(res_block(before_select8, ni=576, ks=3), ni=576, ks=3) #Output: [bs, 576, 8, 8]\n",
        "    \n",
        "    reconstruct16_deconv = deconv_bn_relu(reconstruct8, 576, 512, 3, 2, 1, 1) #Output: [bs, 512, 16, 16]\n",
        "    before_select16 = res_block(feat16, 256) #Output: [bs, 256, 16, 16]\n",
        "    reconstruct16_t = torch.cat((reconstruct16_deconv, before_select16), 1) #Output: [bs, 768, 16, 16]\n",
        "    reconstruct16 = res_block(res_block(reconstruct16_t, ni=768, ks=3), ni=768, ks=3) #Output: [bs, 768, 16, 16]\n",
        "    \n",
        "    reconstruct32_deconv = deconv_bn_relu(reconstruct16, 768, 256, 3, 2, 1, 1) #Output: [bs, 256, 32, 32]\n",
        "    before_select32_t = torch.cat((feat32, initial_32, I_P_32), 1) #Output: [bs, 192, 32, 32]\n",
        "    before_select32 = res_block(before_select32_t, ni=192, ks=3) #Output: [bs, 192, 32, 32]\n",
        "    reconstruct32_t = torch.cat((reconstruct32_deconv, before_select32), 1) #Output: [bs, 448, 32, 32]\n",
        "    reconstruct32 = res_block(res_block(reconstruct32_t, ni=448, ks=3), ni=448, ks=3) #Output: [bs, 448, 32, 32]\n",
        "    img32 = conv_tanh(reconstruct32, ni=448, nf=3, ks=3) #Output: [bs, 3, 32, 32]\n",
        "    \n",
        "    reconstruct64_deconv = deconv_bn_relu(reconstruct32, 448, 128, 3, 2, 1, 1) #Output: [bs, 128, 64, 64]\n",
        "    before_select64_t = torch.cat((feat64, initial_64, I_P_64), 1) #Output: [bs, 112, 64, 64]\n",
        "    before_select64 = res_block(before_select64_t, ni=112, ks=5) #Output: [bs, 112, 64, 64]\n",
        "    reconstruct64_t = torch.cat((reconstruct64_deconv, before_select64), 1) #Output: [bs, 240, 64, 64] \n",
        "    #Not concatenated img32\n",
        "    reconstruct64 = res_block(res_block(reconstruct64_t, ni=240, ks=3), ni=240, ks=3) #Output: [bs, 240, 64, 64]\n",
        "    img64 = conv_tanh(reconstruct64, ni=240, nf=3, ks=3) #Output: [bs, 3, 64, 64]\n",
        "    \n",
        "    reconstruct128_deconv = deconv_bn_relu(reconstruct64, 240, 64, 3, 2, 1, 1) #Output: [bs, 64, 128, 128]\n",
        "    before_select128_t = torch.cat((feat128, initial_128, I_P_128), 1) #Output: [bs, 104, 128, 128]\n",
        "    before_select128 = res_block(before_select128_t, ni=104, ks=7) #Output: [bs, 104, 128, 128]\n",
        "    reconstruct128_t = torch.cat((reconstruct128_deconv, before_select128), 1) #Output: [bs, 168, 128, 128] \n",
        "    #Not concatenated img64, eyel, eyer, nose, mouth, c_eyel, c_eyer, c_nose, c_mouth\n",
        "    reconstruct128 = res_block(reconstruct128_t, ni=168, ks=5) #Output: [bs, 168, 128, 128]\n",
        "    \n",
        "    reconstruct128_1 = conv_bn_lrelu(reconstruct128, ni=168, nf=64, ks=5, stride=1) #Output: [bs, 64, 128, 128]\n",
        "    reconstruct128_1_r = res_block(reconstruct128_1, ni=64) #Output: [bs, 64, 128, 128]\n",
        "    reconstruct128_2 = conv_bn_lrelu(reconstruct128_1_r, ni=64, nf=32, ks=3, stride=1) #Output: [bs, 32, 128, 128]\n",
        "    img128 = conv_tanh(reconstruct128_2, ni=32, nf=3) #Output: [bs, 3, 128, 128]\n",
        "    \n",
        "    return img128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7451a1d",
      "metadata": {
        "id": "b7451a1d"
      },
      "outputs": [],
      "source": [
        "def generator_global_decoder(feat128, feat64, feat32, feat16, feat8, featvec):\n",
        "    \n",
        "    batch_size = featvec.shape[0]\n",
        "    \n",
        "    I_P_32 = torch.randn(batch_size, 32, 32, 32)\n",
        "    I_P_64 = torch.randn(batch_size, 32, 64, 64)\n",
        "    I_P_128 = torch.randn(batch_size, 32, 128, 128)\n",
        "    \n",
        "    #Layer-feat8\n",
        "    noise = torch.randn(batch_size, 256)\n",
        "    _input = torch.cat((featvec, noise), 1)  #Output: [bs, 512]\n",
        "    initial_8 = relu(fc_nn(_input, 512, 64*8*8).reshape([batch_size, 64, 8, 8])) #Output: [bs, 64, 8, 8]\n",
        "    \n",
        "    \n",
        "    #Layer-feat32\n",
        "    initial_32 = relu(deconv_2d(initial_8, 64, 32, 3, 4, 0, 1))  #Output: [bs, 32, 32, 32]\n",
        "    \n",
        "    \n",
        "    #Layer-feat64\n",
        "    initial_64 = relu(deconv_2d(initial_32, 32, 16, 3, 2, 1, 1)) #Output: [bs, 16, 64, 64]\n",
        "\n",
        "    \n",
        "    #Layer-feat128\n",
        "    initial_128 = relu(deconv_2d(initial_64, 16, 8, 3, 2, 1, 1)) #Output: [bs, 8, 128, 128]\n",
        "\n",
        "    \n",
        "    #Layer - deconv0\n",
        "    before_select8_t = torch.cat((initial_8, feat8), 1) #Output: [bs, 576, 8, 8]\n",
        "    before_select8 = res_block(before_select8_t, ni=576, ks=3) #Output: [bs, 576, 8, 8]\n",
        "    reconstruct8 = res_block(res_block(before_select8, ni=576, ks=3), ni=576, ks=3) #Output: [bs, 576, 8, 8]\n",
        "    reconstruct16_deconv = deconv_bn_relu(reconstruct8, 576, 512, 3, 2, 1, 1) #Output: [bs, 512, 16, 16]\n",
        "    \n",
        "    \n",
        "    #Layer - deconv1\n",
        "    before_select16 = res_block(feat16, ni=256) #Output: [bs, 256, 16, 16]\n",
        "    reconstruct16_t = torch.cat((reconstruct16_deconv, before_select16), 1) #Output: [bs, 768, 16, 16]\n",
        "    reconstruct16 = res_block(res_block(reconstruct16_t, ni=768, ks=3), ni=768, ks=3) #Output: [bs, 768, 16, 16]\n",
        "    reconstruct32_deconv = deconv_bn_relu(reconstruct16, 768, 256, 3, 2, 1, 1) #Output: [bs, 256, 32, 32]\n",
        "    \n",
        "    \n",
        "    #Layer - deconv2\n",
        "    before_select32_t = torch.cat((feat32, initial_32, I_P_32), 1) #Output: [bs, 192, 32, 32]\n",
        "    before_select32 = res_block(before_select32_t, ni=192, ks=3) #Output: [bs, 192, 32, 32]\n",
        "    reconstruct32_t = torch.cat((reconstruct32_deconv, before_select32), 1) #Output: [bs, 448, 32, 32]\n",
        "    reconstruct32 = res_block(res_block(reconstruct32_t, ni=448, ks=3), ni=448, ks=3) #Output: [bs, 448, 32, 32]\n",
        "    reconstruct64_deconv = deconv_bn_relu(reconstruct32, 448, 128, 3, 2, 1, 1) #Output: [bs, 128, 64, 64]\n",
        "    \n",
        "    img32 = conv_tanh(reconstruct32, ni=448, nf=3, ks=3) #Output: [bs, 3, 32, 32]\n",
        "    \n",
        "    \n",
        "    #Layer - deconv3\n",
        "    before_select64_t = torch.cat((feat64, initial_64, I_P_64), 1) #Output: [bs, 112, 64, 64]\n",
        "    before_select64 = res_block(before_select64_t, ni=112, ks=5) #Output: [bs, 112, 64, 64]\n",
        "    reconstruct64_t = torch.cat((reconstruct64_deconv, before_select64), 1) #Output: [bs, 240, 64, 64] \n",
        "    #Not concatenated img32\n",
        "    reconstruct64 = res_block(res_block(reconstruct64_t, ni=240, ks=3), ni=240, ks=3) #Output: [bs, 240, 64, 64] \n",
        "    reconstruct128_deconv = deconv_bn_relu(reconstruct64, 240, 64, 3, 2, 1, 1) #Output: [bs, 64, 128, 128]\n",
        "    \n",
        "    img64 = conv_tanh(reconstruct64, ni=240, nf=3, ks=3) #Output: [bs, 3, 64, 64]\n",
        "    \n",
        "    \n",
        "    #Layer - conv5\n",
        "    before_select128_t = torch.cat((feat128, initial_128, I_P_128), 1) #Output: [bs, 104, 128, 128]\n",
        "    before_select128 = res_block(before_select128_t, ni=104, ks=7) #Output: [bs, 104, 128, 128]\n",
        "    reconstruct128_t = torch.cat((reconstruct128_deconv, before_select128), 1) #Output: [bs, 168, 128, 128] \n",
        "    #Not concatenated img64, eyel, eyer, nose, mouth, c_eyel, c_eyer, c_nose, c_mouth\n",
        "    reconstruct128 = res_block(reconstruct128_t, ni=168, ks=5) #Output: [bs, 168, 128, 128]\n",
        "    reconstruct128_1 = conv_bn_lrelu(reconstruct128, ni=168, nf=64, ks=5, stride=1) #Output: [bs, 64, 128, 128]\n",
        "    reconstruct128_1_r = res_block(reconstruct128_1, ni=64) #Output: [bs, 64, 128, 128]\n",
        "    \n",
        "    \n",
        "    #Layer - conv6\n",
        "    reconstruct128_2 = conv_bn_lrelu(reconstruct128_1_r, ni=64, nf=32, ks=3, stride=1) #Output: [bs, 32, 128, 128]\n",
        "    \n",
        "    \n",
        "    #Layer - conv7\n",
        "    img128 = conv_tanh(reconstruct128_2, ni=32, nf=3) #Output: [bs, 3, 128, 128]\n",
        "    \n",
        "    return img128"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://github.com/UnrealLink/TP-GAN"
      ],
      "metadata": {
        "id": "TJ0c1RX8JcVb"
      },
      "id": "TJ0c1RX8JcVb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "TP-GAN_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2a71ae08",
        "e94304ab",
        "84447734",
        "8519f215",
        "709c4dd5",
        "5efd615c",
        "838beab1"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}