{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df8cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "#import cv2\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70216dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu():\n",
    "    return nn.ReLU()\n",
    "\n",
    "def lrelu(f=0.2):\n",
    "    return nn.LeakyReLU(f)\n",
    "\n",
    "def tanh():\n",
    "    return nn.Tanh()\n",
    "\n",
    "def batch_norm(ni):\n",
    "    return nn.BatchNorm2d(ni)\n",
    "\n",
    "def conv_2d(ni, nf, ks, stride=2):\n",
    "    return nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
    "\n",
    "def deconv_2d(ni, nf, ks, stride=2, padding=1, output_padding=1):\n",
    "    return nn.ConvTranspose2d(in_channels=ni, out_channels=nf, \n",
    "                               kernel_size=ks, stride=stride, \n",
    "                               padding=padding, output_padding=output_padding)\n",
    "    \n",
    "def fc_nn(input_size, output_size):\n",
    "    return nn.Sequential(nn.Flatten(), \n",
    "                          nn.Linear(input_size, output_size)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15d30d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, ks=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = conv_2d(ni, ni, ks, stride)\n",
    "        self.bn = batch_norm(ni)\n",
    "        self.lrelu = lrelu()\n",
    "        self.shortcut = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = self.shortcut(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x.add_(r))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "393f49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorGlobal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        dim = [3, 64, 128, 256, 512]\n",
    "        dec = [64, 32, 16, 8]\n",
    "        \n",
    "        #Encoder\n",
    "        self.conv0 = nn.Sequential(\n",
    "                    conv_2d(dim[0], dim[1], ks=7, stride=1),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1], ks=7))\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[1], ks=5, stride=2),\n",
    "                    batch_norm(dim[1]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1], ks=5))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[2], ks=3, stride=2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2], ks=3))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[3], ks=3, stride=2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3], ks=3))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "                    fc_nn(dim[1]*dim[4], dim[4]))\n",
    "\n",
    "        \n",
    "        \n",
    "        #Decoder\n",
    "        \n",
    "        #Layer-feat8 [bs, 64, 8, 8]\n",
    "        self.feat8_ = nn.Sequential(\n",
    "                    fc_nn(dim[4], dim[1]*8*8))\n",
    "        self.feat8 = nn.Sequential(\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat32 [bs, 32, 32, 32]\n",
    "        self.feat32 = nn.Sequential(\n",
    "                    deconv_2d(dec[0], dec[1], 3, 4, 0, 1),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat64 [bs, 16, 64, 64]\n",
    "        self.feat64 = nn.Sequential(\n",
    "                    deconv_2d(dec[1], dec[2], 3, 2, 1, 1),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat128 [bs, 8, 128, 128]\n",
    "        self.feat128 = nn.Sequential(\n",
    "                    deconv_2d(dec[2], dec[3], 3, 2, 1, 1),\n",
    "                    relu())\n",
    "    \n",
    "        #Layer - deconv0 [bs, 512, 16, 16]\n",
    "        self.deconv0_16 = nn.Sequential(\n",
    "                    ResBlock(ni=576),\n",
    "                    ResBlock(ni=576),\n",
    "                    ResBlock(ni=576),\n",
    "                    deconv_2d(576, dim[4], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[4]),\n",
    "                    relu()\n",
    "                    )\n",
    "        \n",
    "        #Layer - deconv1 [bs, 256, 32, 32]\n",
    "        \n",
    "    select16_res_1 = res_block(conv3, ni=256) #Output: [bs, 256, 16, 16]\n",
    "    dec16_res2_t = torch.cat((deconv0_16, select16_res_1), 1) #Output: [bs, 768, 16, 16]\n",
    "    dec16_res2 = res_block(res_block(dec16_res2_t, ni=768, ks=3), ni=768, ks=3) #Output: [bs, 768, 16, 16]\n",
    "    deconv1_32 = deconv_bn_relu(dec16_res2, 768, 256, 3, 2, 1, 1) #Output: [bs, 256, 32, 32]\n",
    "        \n",
    "    def forward(self, x, noise):\n",
    "        conv0 = self.conv0(x)\n",
    "        conv1 = self.conv1(conv0)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        fc1 = self.fc1(conv4)\n",
    "        fc2 = torch.maximum(fc1[:, 0:256], fc1[:, 256:])\n",
    "        \n",
    "        feat8_ = self.feat8_(torch.cat((fc2, noise), 1)).view(fc2.size()[0], 64, 8, 8) #Output: [bs, 64, 8, 8]\n",
    "        feat8 = self.feat8(feat8_) #Output: [bs, 64, 8, 8]\n",
    "        \n",
    "        feat32 = self.feat32(feat8) #Output: [bs, 32, 32, 32]\n",
    "        \n",
    "        feat64 = self.feat64(feat32) #Output: [bs, 16, 64, 64]\n",
    "        \n",
    "        feat128 = self.feat128(feat64) #Output: [bs, 8, 128, 128]\n",
    "        \n",
    "        deconv0_16 = self.deconv0_16(torch.cat((feat8, conv4), 1)) #Output: [bs, 512, 16, 16]\n",
    "        \n",
    "        deconv1_32 = self.deconv1_32()\n",
    "        \n",
    "        #return conv0, conv1, conv2, conv3, conv4, fc2\n",
    "        return deconv0_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "83304d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 512, 16, 16])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(49, 3, 128, 128)\n",
    "noi = torch.randn(49, 256)\n",
    "\n",
    "model = GeneratorGlobal()\n",
    "feats = model(input1, noi)\n",
    "\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86663b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_global_decoder(conv0, conv1, conv2, conv3, conv4, fc):\n",
    "    \n",
    "    '''\n",
    "    conv0 : [batch_size, 64, 128, 128]\n",
    "    conv1 : [batch_size, 64, 64, 64]\n",
    "    conv2 : [batch_size, 128, 32, 32]\n",
    "    conv3 : [batch_size, 256, 16, 16]\n",
    "    conv4 : [batch_size, 512, 8, 8]\n",
    "       fc : [batch_size, 256]\n",
    "    '''\n",
    "    \n",
    "    batch_size = fc.shape[0]\n",
    "    \n",
    "    I_P_32 = torch.randn(batch_size, 32, 32, 32)\n",
    "    I_P_64 = torch.randn(batch_size, 32, 64, 64)\n",
    "    I_P_128 = torch.randn(batch_size, 32, 128, 128)\n",
    "    \n",
    "    #Layer - deconv2 [bs, 128, 64, 64]\n",
    "    select32_res_1_t = torch.cat((conv2, feat32, I_P_32), 1) #Output: [bs, 192, 32, 32]\n",
    "    select32_res_1 = res_block(select32_res_1_t, ni=192, ks=3) #Output: [bs, 192, 32, 32]\n",
    "    dec32_res2_t = torch.cat((deconv1_32, select32_res_1), 1) #Output: [bs, 448, 32, 32]\n",
    "    dec32_res2 = res_block(res_block(dec32_res2_t, ni=448, ks=3), ni=448, ks=3) #Output: [bs, 448, 32, 32]\n",
    "    deconv2_64 = deconv_bn_relu(dec32_res2, 448, 128, 3, 2, 1, 1) #Output: [bs, 128, 64, 64]\n",
    "    \n",
    "    img32 = conv_tanh(dec32_res2, ni=448, nf=3, ks=3) #Output: [bs, 3, 32, 32]\n",
    "    \n",
    "    \n",
    "    #Layer - deconv3 [bs, 64, 128, 128]\n",
    "    select64_res_1_t = torch.cat((conv1, feat64, I_P_64), 1) #Output: [bs, 112, 64, 64]\n",
    "    select64_res_1 = res_block(select64_res_1_t, ni=112, ks=5) #Output: [bs, 112, 64, 64]\n",
    "    dec64_res2_t = torch.cat((deconv2_64, select64_res_1), 1) #Output: [bs, 240, 64, 64] \n",
    "    #Not concatenated img32\n",
    "    dec64_res2 = res_block(res_block(dec64_res2_t, ni=240, ks=3), ni=240, ks=3) #Output: [bs, 240, 64, 64] \n",
    "    deconv3_128 = deconv_bn_relu(dec64_res2, 240, 64, 3, 2, 1, 1) #Output: [bs, 64, 128, 128]\n",
    "    \n",
    "    img64 = conv_tanh(dec64_res2, ni=240, nf=3, ks=3) #Output: [bs, 3, 64, 64]\n",
    "    \n",
    "    \n",
    "    #Layer - conv5 [bs, 64, 128, 128]\n",
    "    select128_res_1_t = torch.cat((conv0, feat128, I_P_128), 1) #Output: [bs, 104, 128, 128]\n",
    "    select128_res_1 = res_block(select128_res_1_t, ni=104, ks=7) #Output: [bs, 104, 128, 128]\n",
    "    dec128_res2_t = torch.cat((deconv3_128, select128_res_1), 1) #Output: [bs, 168, 128, 128] \n",
    "    #Not concatenated img64, eyel, eyer, nose, mouth, c_eyel, c_eyer, c_nose, c_mouth\n",
    "    dec128_res2 = res_block(dec128_res2_t, ni=168, ks=5) #Output: [bs, 168, 128, 128]\n",
    "    dec128_conv5 = conv_bn_lrelu(dec128_res2, ni=168, nf=64, ks=5, stride=1) #Output: [bs, 64, 128, 128]\n",
    "    dec128_conv5_r = res_block(dec128_conv5, ni=64) #Output: [bs, 64, 128, 128]\n",
    "    \n",
    "    \n",
    "    #Layer - conv6 [bs, 32, 128, 128]\n",
    "    dec128_conv6 = conv_bn_lrelu(dec128_conv5_r, ni=64, nf=32, ks=3, stride=1) #Output: [bs, 32, 128, 128]\n",
    "    \n",
    "    \n",
    "    #Layer - conv7 [bs, 3, 128, 128]\n",
    "    img128 = conv_tanh(dec128_conv6, ni=32, nf=3) #Output: [bs, 3, 128, 128]\n",
    "    \n",
    "    return img128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f76653fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive(a1, a2, a3, a4, a5, a6):\n",
    "    print(a1.shape)\n",
    "    print(a2.shape)\n",
    "    print(a3.shape)\n",
    "    print(a4.shape)\n",
    "    print(a5.shape)\n",
    "    print(a6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "90e59508",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeneratorGlobal' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3584/3665863166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneratorGlobal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreceive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3584/888670807.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1186\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneratorGlobal' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(49, 3, 128, 128)\n",
    "model = GeneratorGlobal()\n",
    "feats = model(input1)\n",
    "\n",
    "receive(*feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21606b86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
