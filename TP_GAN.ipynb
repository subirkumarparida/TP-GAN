{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df8cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "#import cv2\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70216dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu():\n",
    "    return nn.ReLU()\n",
    "\n",
    "def lrelu(f=0.2):\n",
    "    return nn.LeakyReLU(f)\n",
    "\n",
    "def tanh():\n",
    "    return nn.Tanh()\n",
    "\n",
    "def batch_norm(ni):\n",
    "    return nn.BatchNorm2d(ni)\n",
    "\n",
    "def conv_2d(ni, nf, ks, stride=2):\n",
    "    return nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
    "\n",
    "def deconv_2d(ni, nf, ks, stride=2, padding=1, output_padding=1):\n",
    "    return nn.ConvTranspose2d(in_channels=ni, out_channels=nf, \n",
    "                               kernel_size=ks, stride=stride, \n",
    "                               padding=padding, output_padding=output_padding)\n",
    "    \n",
    "def fc_nn(input_size, output_size):\n",
    "    return nn.Sequential(nn.Flatten(), \n",
    "                          nn.Linear(input_size, output_size)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d30d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, ks=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = conv_2d(ni, ni, ks, stride)\n",
    "        self.bn = batch_norm(ni)\n",
    "        self.lrelu = lrelu()\n",
    "        self.shortcut = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = self.shortcut(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x.add_(r))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad70c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shapes(*feats):\n",
    "    for f in feats:\n",
    "        print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393f49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorGlobal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        dim = [3, 64, 128, 256, 512]\n",
    "        dec = [64, 32, 16, 8]\n",
    "        \n",
    "        \n",
    "        #Encoder\n",
    "        self.conv0 = nn.Sequential(\n",
    "                    conv_2d(dim[0], dim[1], ks=7, stride=1),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1], ks=7))\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[1], ks=5, stride=2),\n",
    "                    batch_norm(dim[1]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1], ks=5))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[2], ks=3, stride=2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2], ks=3))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[3], ks=3, stride=2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3], ks=3))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "                    fc_nn(dim[1]*dim[4], dim[4]))\n",
    "\n",
    "        \n",
    "        \n",
    "        #Decoder\n",
    "        \n",
    "        #Layer-feat8 [bs, 64, 8, 8]\n",
    "        self.feat8_ = nn.Sequential(\n",
    "                    fc_nn(dim[4], dim[1]*8*8))\n",
    "        self.feat8 = nn.Sequential(\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat32 [bs, 32, 32, 32]\n",
    "        self.feat32 = nn.Sequential(\n",
    "                    deconv_2d(dec[0], dec[1], 3, 4, 0, 1),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat64 [bs, 16, 64, 64]\n",
    "        self.feat64 = nn.Sequential(\n",
    "                    deconv_2d(dec[1], dec[2], 3, 2, 1, 1),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat128 [bs, 8, 128, 128]\n",
    "        self.feat128 = nn.Sequential(\n",
    "                    deconv_2d(dec[2], dec[3], 3, 2, 1, 1),\n",
    "                    relu())\n",
    "    \n",
    "        #Layer - deconv0 [bs, 512, 16, 16]\n",
    "        self.deconv0_16 = nn.Sequential(\n",
    "                    ResBlock(ni=576),\n",
    "                    ResBlock(ni=576),\n",
    "                    ResBlock(ni=576),\n",
    "                    deconv_2d(576, dim[4], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[4]),\n",
    "                    relu()\n",
    "                    )\n",
    "        \n",
    "        #Layer - deconv1 [bs, 256, 32, 32]\n",
    "        self.decode_16 = nn.Sequential(\n",
    "                    ResBlock(ni=256)\n",
    "                    )\n",
    "        \n",
    "        self.deconv1_32 = nn.Sequential(\n",
    "                    ResBlock(ni=768),\n",
    "                    ResBlock(ni=768),\n",
    "                    deconv_2d(768, dim[3], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[3]),\n",
    "                    relu()\n",
    "                    )\n",
    "        \n",
    "        #Layer - deconv2 [bs, 128, 64, 64]\n",
    "        self.decode_32 = nn.Sequential(\n",
    "                    ResBlock(ni=192)\n",
    "                    )\n",
    "        \n",
    "        self.reconstruct_32 = nn.Sequential(\n",
    "                    ResBlock(ni=448),\n",
    "                    ResBlock(ni=448)\n",
    "                    )\n",
    "        \n",
    "        self.deconv2_64 = nn.Sequential(\n",
    "                    deconv_2d(448, dim[2], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[2]),\n",
    "                    relu()\n",
    "                    )\n",
    "        \n",
    "        self.img32 = nn.Sequential(\n",
    "                    conv_2d(ni=448, nf=dim[0], ks=3, stride=1),\n",
    "                    tanh()\n",
    "                    )\n",
    "        \n",
    "        #Layer - deconv3 [bs, 64, 128, 128]\n",
    "        self.decode_64 = nn.Sequential(\n",
    "                    ResBlock(ni=112, ks=5)\n",
    "                    )\n",
    "        \n",
    "        self.reconstruct_64 = nn.Sequential(\n",
    "                    ResBlock(ni=240),\n",
    "                    ResBlock(ni=240)\n",
    "                    )\n",
    "        \n",
    "        self.deconv3_128 = nn.Sequential(\n",
    "                    deconv_2d(240, dim[1], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[1]),\n",
    "                    relu()\n",
    "                    )\n",
    "        \n",
    "        self.img64 = nn.Sequential(\n",
    "                    conv_2d(ni=240, nf=dim[0], ks=3, stride=1),\n",
    "                    tanh()\n",
    "                    )\n",
    "        \n",
    "        #Layer - conv5 [bs, 64, 128, 128]\n",
    "        self.decode_128 = nn.Sequential(\n",
    "                    ResBlock(ni=104, ks=7)\n",
    "                    )\n",
    "        \n",
    "        self.reconstruct_128 = nn.Sequential(\n",
    "                    ResBlock(ni=168, ks=5)                    \n",
    "                    )\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "                    conv_2d(168, dec[0], ks=5, stride=1),\n",
    "                    batch_norm(dec[0]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(ni=dec[0])\n",
    "                    )\n",
    "\n",
    "        #Layer - conv6 [bs, 32, 128, 128]\n",
    "        self.conv6 = nn.Sequential(\n",
    "                    conv_2d(dec[0], dec[1], ks=3, stride=1),\n",
    "                    batch_norm(dec[1]),\n",
    "                    lrelu()\n",
    "                    )\n",
    "        \n",
    "        #Layer - conv7 [bs, 3, 128, 128]\n",
    "        self.img128 = nn.Sequential(\n",
    "                    conv_2d(ni=dec[1], nf=dim[0], ks=3, stride=1),\n",
    "                    tanh()\n",
    "                    )\n",
    "\n",
    "    \n",
    "    def forward(self, x, noise, I_P_32, I_P_64, I_P_128):\n",
    "        conv0 = self.conv0(x)\n",
    "        conv1 = self.conv1(conv0)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        fc1 = self.fc1(conv4)\n",
    "        fc2 = torch.maximum(fc1[:, 0:256], fc1[:, 256:])\n",
    "        \n",
    "        feat8_ = self.feat8_(torch.cat((fc2, noise), 1)).view(fc2.size()[0], 64, 8, 8) #Output: [bs, 64, 8, 8]\n",
    "        feat8 = self.feat8(feat8_) #Output: [bs, 64, 8, 8]\n",
    "        \n",
    "        feat32 = self.feat32(feat8) #Output: [bs, 32, 32, 32]\n",
    "        \n",
    "        feat64 = self.feat64(feat32) #Output: [bs, 16, 64, 64]\n",
    "        \n",
    "        feat128 = self.feat128(feat64) #Output: [bs, 8, 128, 128]\n",
    "        \n",
    "        deconv0_16 = self.deconv0_16(torch.cat((feat8, conv4), 1)) #Output: [bs, 512, 16, 16]\n",
    "        \n",
    "        decode_16 = self.decode_16(conv3)\n",
    "        deconv1_32 = self.deconv1_32(torch.cat((deconv0_16, decode_16), 1)) #Output: [bs, 256, 32, 32]\n",
    "        \n",
    "        decode_32 = self.decode_32(torch.cat((conv2, feat32, I_P_32), 1))\n",
    "        reconstruct_32 = self.reconstruct_32(torch.cat((deconv1_32, decode_32), 1))\n",
    "        deconv2_64 = self.deconv2_64(reconstruct_32) #Output: [bs, 128, 64, 64]\n",
    "        img32 = self.img32(reconstruct_32) #Output: [bs, 3, 32, 32]\n",
    "        \n",
    "        decode_64 = self.decode_64(torch.cat((conv1, feat64, I_P_64), 1))\n",
    "        reconstruct_64 = self.reconstruct_64(torch.cat((deconv2_64, decode_64), 1)) #Not concatenated img32\n",
    "        deconv3_128 = self.deconv3_128(reconstruct_64) #Output: [bs, 64, 128, 128]\n",
    "        img64 = self.img64(reconstruct_64) #Output: [bs, 3, 64, 64]\n",
    "        \n",
    "        decode_128 = self.decode_128(torch.cat((conv0, feat128, I_P_128), 1))\n",
    "        reconstruct_128 = self.reconstruct_128(torch.cat((deconv3_128, decode_128), 1)) #Not concatenated img64, eyel, eyer, nose, mouth, c_eyel, c_eyer, c_nose, c_mouth\n",
    "        conv5 = self.conv5(reconstruct_128) #Output: [bs, 64, 128, 128]\n",
    "        \n",
    "        conv6 = self.conv6(conv5) #Output: [bs, 32, 128, 128]\n",
    "        \n",
    "        img128 = self.img128(conv6) #Output: [bs, 3, 128, 128]\n",
    "        \n",
    "        \n",
    "        return img128, img64, img32, fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83304d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 49\n",
    "input1 = torch.randn(batch_size, 3, 128, 128)\n",
    "noi = torch.randn(batch_size, 256)\n",
    "\n",
    "I_P_32 = torch.randn(batch_size, 32, 32, 32)\n",
    "I_P_64 = torch.randn(batch_size, 32, 64, 64)\n",
    "I_P_128 = torch.randn(batch_size, 32, 128, 128)\n",
    "        \n",
    "\n",
    "model = GeneratorGlobal()\n",
    "feats = model(input1, noi, I_P_32, I_P_64, I_P_128)\n",
    "\n",
    "#feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af44c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 3, 128, 128])\n",
      "torch.Size([49, 3, 64, 64])\n",
      "torch.Size([49, 3, 32, 32])\n",
      "torch.Size([49, 256])\n"
     ]
    }
   ],
   "source": [
    "show_shapes(*feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86663b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorLocal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        dim = [3, 64, 128, 256, 512]\n",
    "        dec = [64, 32, 16, 8]\n",
    "        \n",
    "        \n",
    "        #Encoder\n",
    "        \n",
    "        #Layer: conv0, Output: [batch_size, 64, w, h]\n",
    "        self.conv0 = nn.Sequential(\n",
    "                    conv_2d(dim[0], dim[1], ks=3, stride=1),\n",
    "                    relu(),\n",
    "                    ResBlock(dim[1])\n",
    "                    )\n",
    "        \n",
    "        #Layer: conv1, Output: [batch_size, 128, w/2, h/2]\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[2], ks=3, stride=2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2])\n",
    "                    )\n",
    "        \n",
    "        #Layer: conv2, Output: [batch_size, 256, w/4, h/4]\n",
    "        self.conv2 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[3], ks=3, stride=2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3])\n",
    "                    )\n",
    "        \n",
    "        #Layer: conv3, Output: [batch_size, 512, w/8, h/8]\n",
    "        self.conv3 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[4]),\n",
    "                    ResBlock(dim[4])\n",
    "                    )\n",
    "        \n",
    " \n",
    "        #Decoder\n",
    "        \n",
    "        #Layer: deconv0, Output: [batch_size, 256, w/4, h/4]\n",
    "        self.deconv0 = nn.Sequential(\n",
    "                    deconv_2d(dim[4], dim[3], 3, 2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer: deconv1, Output: [batch_size, 128, w/2, h/2]\n",
    "        self.deconv1 = nn.Sequential(\n",
    "                    conv_2d(dim[4], dim[3], ks=3, stride=1),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3]),\n",
    "                    deconv_2d(dim[3], dim[2], 3, 2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer: deconv2, Output: [batch_size, 64, w, h]\n",
    "        self.deconv2 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[2], ks=3, stride=1),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2]),\n",
    "                    deconv_2d(dim[2], dim[1], 3, 2),\n",
    "                    batch_norm(dim[1]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer: conv4, Output: [batch_size, 64, w, h]\n",
    "        self.conv4 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[1], ks=3, stride=1),\n",
    "                    batch_norm(dim[1]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1]))\n",
    "        \n",
    "        #Layer: conv5, Output: [batch_size, 3, w, h]\n",
    "        self.conv5 = nn.Sequential(\n",
    "                    conv_2d(ni=dim[1], nf=dim[0], ks=3, stride=1),\n",
    "                    tanh()\n",
    "                    )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv0 = self.conv0(x)      #Output: [batch_size, 64, w, h]\n",
    "        conv1 = self.conv1(conv0)  #Output: [batch_size, 128, w/2, h/2]\n",
    "        conv2 = self.conv2(conv1)  #Output: [batch_size, 256, w/4, h/4]\n",
    "        conv3 = self.conv3(conv2)  #Output: [batch_size, 512, w/8, h/8]\n",
    "\n",
    "        deconv0 = self.deconv0(conv3) #Output: [batch_size, 256, w/4, h/4]\n",
    "        \n",
    "        deconv1 = self.deconv1(torch.cat((deconv0, conv2), 1)) #Output: [batch_size, 128, w/2, h/2]\n",
    "        \n",
    "        deconv2 = self.deconv2(torch.cat((deconv1, conv1), 1)) #Output: [batch_size, 64, w, h]\n",
    "        \n",
    "        conv4 = self.conv4(torch.cat((deconv2, conv0), 1))     #Output: [batch_size, 64, w, h]\n",
    "        \n",
    "        conv5 = self.conv5(conv4)   #Output: [batch_size, 3, w, h]\n",
    "        \n",
    "        \n",
    "        return conv5, conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa32815",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(45, 3, 8, 8)\n",
    "model = GeneratorLocal()\n",
    "output1 = model(input1)\n",
    "\n",
    "#output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e59508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 3, 8, 8])\n",
      "torch.Size([45, 64, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "show_shapes(*output1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
