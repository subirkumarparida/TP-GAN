{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350963c7",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df8cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "#import cv2\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70216dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu():\n",
    "    return nn.ReLU()\n",
    "\n",
    "def lrelu(f=0.2):\n",
    "    return nn.LeakyReLU(f)\n",
    "\n",
    "def tanh():\n",
    "    return nn.Tanh()\n",
    "\n",
    "def batch_norm(ni):\n",
    "    return nn.BatchNorm2d(ni)\n",
    "\n",
    "def conv_2d(ni, nf, ks, stride=2):\n",
    "    return nn.Conv2d(in_channels=ni, out_channels=nf, kernel_size=ks, stride=stride, padding=ks//2, bias=False)\n",
    "\n",
    "def deconv_2d(ni, nf, ks, stride=2, padding=1, output_padding=1):\n",
    "    return nn.ConvTranspose2d(in_channels=ni, out_channels=nf, \n",
    "                               kernel_size=ks, stride=stride, \n",
    "                               padding=padding, output_padding=output_padding)\n",
    "    \n",
    "def fc_nn(input_size, output_size):\n",
    "    return nn.Sequential(nn.Flatten(), \n",
    "                          nn.Linear(input_size, output_size)\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d30d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, ks=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = conv_2d(ni, ni, ks, stride)\n",
    "        self.bn = batch_norm(ni)\n",
    "        self.lrelu = lrelu()\n",
    "        self.shortcut = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = self.shortcut(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x.add_(r))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad70c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shapes(*feats):\n",
    "    for f in feats:\n",
    "        print(f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef5be9",
   "metadata": {},
   "source": [
    "### Generator: Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "393f49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorGlobal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        dim = [3, 64, 128, 256, 512]\n",
    "        dec = [64, 32, 16, 8]\n",
    "        \n",
    "        \n",
    "        #Encoder\n",
    "        #---------------\n",
    "        \n",
    "        self.conv0 = nn.Sequential(\n",
    "                    conv_2d(dim[0], dim[1], ks=7, stride=1),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1], ks=7))\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[1], ks=5, stride=2),\n",
    "                    batch_norm(dim[1]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1], ks=5))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[2], ks=3, stride=2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2], ks=3))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[3], ks=3, stride=2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3], ks=3))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3),\n",
    "                    ResBlock(dim[4], ks=3))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "                    fc_nn(dim[1]*dim[4], dim[4]))\n",
    "\n",
    "        \n",
    "        \n",
    "        #Decoder\n",
    "        #---------------\n",
    "        \n",
    "        #Layer-feat8 [bs, 64, 8, 8]\n",
    "        self.feat8_ = nn.Sequential(\n",
    "                    fc_nn(dim[4], dim[1]*8*8))\n",
    "        self.feat8 = nn.Sequential(\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat32 [bs, 32, 32, 32]\n",
    "        self.feat32 = nn.Sequential(\n",
    "                    deconv_2d(dec[0], dec[1], 3, 4, 0, 1),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat64 [bs, 16, 64, 64]\n",
    "        self.feat64 = nn.Sequential(\n",
    "                    deconv_2d(dec[1], dec[2], 3, 2, 1, 1),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer-feat128 [bs, 8, 128, 128]\n",
    "        self.feat128 = nn.Sequential(\n",
    "                    deconv_2d(dec[2], dec[3], 3, 2, 1, 1),\n",
    "                    relu())\n",
    "    \n",
    "        #Layer - deconv0 [bs, 512, 16, 16]\n",
    "        self.deconv0_16 = nn.Sequential(\n",
    "                    ResBlock(ni=576),\n",
    "                    ResBlock(ni=576),\n",
    "                    ResBlock(ni=576),\n",
    "                    deconv_2d(576, dim[4], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[4]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer - deconv1 [bs, 256, 32, 32]\n",
    "        self.decode_16 = nn.Sequential(\n",
    "                    ResBlock(ni=256))\n",
    "        \n",
    "        self.deconv1_32 = nn.Sequential(\n",
    "                    ResBlock(ni=768),\n",
    "                    ResBlock(ni=768),\n",
    "                    deconv_2d(768, dim[3], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[3]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer - deconv2 [bs, 128, 64, 64]\n",
    "        self.decode_32 = nn.Sequential(\n",
    "                    ResBlock(ni=192))\n",
    "        \n",
    "        self.reconstruct_32 = nn.Sequential(\n",
    "                    ResBlock(ni=448),\n",
    "                    ResBlock(ni=448))\n",
    "        \n",
    "        self.deconv2_64 = nn.Sequential(\n",
    "                    deconv_2d(448, dim[2], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[2]),\n",
    "                    relu())\n",
    "        \n",
    "        self.img32 = nn.Sequential(\n",
    "                    conv_2d(ni=448, nf=dim[0], ks=3, stride=1),\n",
    "                    tanh())\n",
    "        \n",
    "        #Layer - deconv3 [bs, 64, 128, 128]\n",
    "        self.decode_64 = nn.Sequential(\n",
    "                    ResBlock(ni=112, ks=5))\n",
    "        \n",
    "        self.reconstruct_64 = nn.Sequential(\n",
    "                    ResBlock(ni=240),\n",
    "                    ResBlock(ni=240))\n",
    "        \n",
    "        self.deconv3_128 = nn.Sequential(\n",
    "                    deconv_2d(240, dim[1], 3, 2, 1, 1),\n",
    "                    batch_norm(dim[1]),\n",
    "                    relu())\n",
    "        \n",
    "        self.img64 = nn.Sequential(\n",
    "                    conv_2d(ni=240, nf=dim[0], ks=3, stride=1),\n",
    "                    tanh())\n",
    "        \n",
    "        #Layer - conv5 [bs, 64, 128, 128]\n",
    "        self.decode_128 = nn.Sequential(\n",
    "                    ResBlock(ni=75, ks=7))\n",
    "        \n",
    "        self.reconstruct_128 = nn.Sequential(\n",
    "                    ResBlock(ni=139, ks=5))\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "                    conv_2d(139, dec[0], ks=5, stride=1),\n",
    "                    batch_norm(dec[0]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(ni=dec[0]))\n",
    "\n",
    "        #Layer - conv6 [bs, 32, 128, 128]\n",
    "        self.conv6 = nn.Sequential(\n",
    "                    conv_2d(dec[0], dec[1], ks=3, stride=1),\n",
    "                    batch_norm(dec[1]),\n",
    "                    lrelu())\n",
    "        \n",
    "        #Layer - conv7 [bs, 3, 128, 128]\n",
    "        self.img128 = nn.Sequential(\n",
    "                    conv_2d(ni=dec[1], nf=dim[0], ks=3, stride=1),\n",
    "                    tanh())\n",
    "\n",
    "    def forward(self, I_P_128, I_P_64, I_P_32, local_predict, local_feature, noise):\n",
    "        conv0 = self.conv0(I_P_128)\n",
    "        conv1 = self.conv1(conv0)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        fc1 = self.fc1(conv4)\n",
    "        fc2 = torch.maximum(fc1[:, 0:256], fc1[:, 256:])\n",
    "        \n",
    "        feat8_ = self.feat8_(torch.cat((fc2, noise), 1)).view(fc2.size()[0], 64, 8, 8) #Output: [bs, 64, 8, 8]\n",
    "        feat8 = self.feat8(feat8_) #Output: [bs, 64, 8, 8]\n",
    "        \n",
    "        feat32 = self.feat32(feat8) #Output: [bs, 32, 32, 32]\n",
    "        \n",
    "        feat64 = self.feat64(feat32) #Output: [bs, 16, 64, 64]\n",
    "        \n",
    "        feat128 = self.feat128(feat64) #Output: [bs, 8, 128, 128]\n",
    "        \n",
    "        deconv0_16 = self.deconv0_16(torch.cat((feat8, conv4), 1)) #Output: [bs, 512, 16, 16]\n",
    "        \n",
    "        decode_16 = self.decode_16(conv3)\n",
    "        deconv1_32 = self.deconv1_32(torch.cat((deconv0_16, decode_16), 1)) #Output: [bs, 256, 32, 32]\n",
    "        \n",
    "        decode_32 = self.decode_32(torch.cat((conv2, feat32, I_P_32), 1))\n",
    "        reconstruct_32 = self.reconstruct_32(torch.cat((deconv1_32, decode_32), 1))\n",
    "        deconv2_64 = self.deconv2_64(reconstruct_32) #Output: [bs, 128, 64, 64]\n",
    "        img32 = self.img32(reconstruct_32) #Output: [bs, 3, 32, 32]\n",
    "        \n",
    "        decode_64 = self.decode_64(torch.cat((conv1, feat64, I_P_64), 1))\n",
    "        reconstruct_64 = self.reconstruct_64(torch.cat((deconv2_64, decode_64), 1)) #Not concatenated img32\n",
    "        deconv3_128 = self.deconv3_128(reconstruct_64) #Output: [bs, 64, 128, 128]\n",
    "        img64 = self.img64(reconstruct_64) #Output: [bs, 3, 64, 64]\n",
    "        \n",
    "        decode_128 = self.decode_128(torch.cat((conv0, feat128, I_P_128), 1))\n",
    "        reconstruct_128 = self.reconstruct_128(torch.cat((deconv3_128, decode_128), 1)) #Not concatenated img64, eyel, eyer, nose, mouth, c_eyel, c_eyer, c_nose, c_mouth\n",
    "        conv5 = self.conv5(reconstruct_128) #Output: [bs, 64, 128, 128]\n",
    "        \n",
    "        conv6 = self.conv6(conv5) #Output: [bs, 32, 128, 128]\n",
    "        \n",
    "        img128 = self.img128(conv6) #Output: [bs, 3, 128, 128]\n",
    "        \n",
    "        \n",
    "        return img128, img64, img32, fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83304d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 49\n",
    "input1 = torch.randn(batch_size, 3, 128, 128)\n",
    "noi = torch.randn(batch_size, 256)\n",
    "\n",
    "I_P_32 = torch.randn(batch_size, 32, 32, 32)\n",
    "I_P_64 = torch.randn(batch_size, 32, 64, 64)\n",
    "I_P_128 = torch.randn(batch_size, 3, 128, 128)\n",
    "        \n",
    "\n",
    "model = GeneratorGlobal()\n",
    "feats = model(I_P_128, I_P_64, I_P_32, input1, input1, noi)\n",
    "\n",
    "#feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af44c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 3, 128, 128])\n",
      "torch.Size([49, 3, 64, 64])\n",
      "torch.Size([49, 3, 32, 32])\n",
      "torch.Size([49, 256])\n"
     ]
    }
   ],
   "source": [
    "show_shapes(*feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263db0f",
   "metadata": {},
   "source": [
    "### Generator: Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86663b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorLocal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        dim = [3, 64, 128, 256, 512]\n",
    "        dec = [64, 32, 16, 8]\n",
    "        \n",
    "        \n",
    "        #Encoder\n",
    "        #---------------\n",
    "        \n",
    "        #Layer: conv0, Output: [batch_size, 64, w, h]\n",
    "        self.conv0 = nn.Sequential(\n",
    "                    conv_2d(dim[0], dim[1], ks=3, stride=1),\n",
    "                    relu(),\n",
    "                    ResBlock(dim[1]))\n",
    "        \n",
    "        #Layer: conv1, Output: [batch_size, 128, w/2, h/2]\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[2], ks=3, stride=2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2]))\n",
    "        \n",
    "        #Layer: conv2, Output: [batch_size, 256, w/4, h/4]\n",
    "        self.conv2 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[3], ks=3, stride=2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3]))\n",
    "        \n",
    "        #Layer: conv3, Output: [batch_size, 512, w/8, h/8]\n",
    "        self.conv3 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[4]),\n",
    "                    ResBlock(dim[4]))\n",
    "        \n",
    " \n",
    "        #Decoder\n",
    "        #---------------\n",
    "        \n",
    "        #Layer: deconv0, Output: [batch_size, 256, w/4, h/4]\n",
    "        self.deconv0 = nn.Sequential(\n",
    "                    deconv_2d(dim[4], dim[3], 3, 2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer: deconv1, Output: [batch_size, 128, w/2, h/2]\n",
    "        self.deconv1 = nn.Sequential(\n",
    "                    conv_2d(dim[4], dim[3], ks=3, stride=1),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[3]),\n",
    "                    deconv_2d(dim[3], dim[2], 3, 2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer: deconv2, Output: [batch_size, 64, w, h]\n",
    "        self.deconv2 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[2], ks=3, stride=1),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[2]),\n",
    "                    deconv_2d(dim[2], dim[1], 3, 2),\n",
    "                    batch_norm(dim[1]),\n",
    "                    relu())\n",
    "        \n",
    "        #Layer: conv4, Output: [batch_size, 64, w, h]\n",
    "        self.conv4 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[1], ks=3, stride=1),\n",
    "                    batch_norm(dim[1]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(dim[1]))\n",
    "        \n",
    "        #Layer: conv5, Output: [batch_size, 3, w, h]\n",
    "        self.conv5 = nn.Sequential(\n",
    "                    conv_2d(ni=dim[1], nf=dim[0], ks=3, stride=1),\n",
    "                    tanh())\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv0 = self.conv0(x)      #Output: [batch_size, 64, w, h]\n",
    "        conv1 = self.conv1(conv0)  #Output: [batch_size, 128, w/2, h/2]\n",
    "        conv2 = self.conv2(conv1)  #Output: [batch_size, 256, w/4, h/4]\n",
    "        conv3 = self.conv3(conv2)  #Output: [batch_size, 512, w/8, h/8]\n",
    "\n",
    "        deconv0 = self.deconv0(conv3) #Output: [batch_size, 256, w/4, h/4]\n",
    "        \n",
    "        deconv1 = self.deconv1(torch.cat((deconv0, conv2), 1)) #Output: [batch_size, 128, w/2, h/2]\n",
    "        \n",
    "        deconv2 = self.deconv2(torch.cat((deconv1, conv1), 1)) #Output: [batch_size, 64, w, h]\n",
    "        \n",
    "        conv4 = self.conv4(torch.cat((deconv2, conv0), 1))     #Output: [batch_size, 64, w, h]\n",
    "        \n",
    "        conv5 = self.conv5(conv4)   #Output: [batch_size, 3, w, h]\n",
    "        \n",
    "        \n",
    "        return conv5, conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa32815",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(45, 3, 8, 8)\n",
    "model = GeneratorLocal()\n",
    "output1 = model(input1)\n",
    "\n",
    "#output1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e59508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 3, 8, 8])\n",
      "torch.Size([45, 64, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "show_shapes(*output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104a31b",
   "metadata": {},
   "source": [
    "### Local Fusion of eyes, nose, mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86d463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalFuser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "               \n",
    "        \n",
    "    def forward(self, leye, reye, nose, mouth):\n",
    "        p_leye = F.pad(leye, (76, 128-(76+leye.shape[-1]), 38, 128-(38+leye.shape[-2])))\n",
    "        p_reye = F.pad(reye, (21, 128-(21+reye.shape[-1]), 38, 128-(38+reye.shape[-2])))\n",
    "        p_nose = F.pad(nose, (47, 128-(47+nose.shape[-1]), 37, 128-(37+nose.shape[-2])))\n",
    "        p_mouth = F.pad(mouth, (42, 128-(42+mouth.shape[-1]), 86, 128-(86+mouth.shape[-2])))\n",
    "        \n",
    "        return torch.max(torch.stack([p_leye, p_reye, p_nose, p_mouth], dim=0), dim=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd814e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 3, 128, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leye = torch.randn(45, 3, 128, 128)\n",
    "\n",
    "model = LocalFuser()\n",
    "output4 = model(leye, leye, leye, leye)\n",
    "\n",
    "output4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf9007",
   "metadata": {},
   "source": [
    "### Feature Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9530a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePredict(nn.Module):\n",
    "    def __init__(self, num_classes, dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc672cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input3 = torch.randn(256)\n",
    "model = FeaturePredict(num_classes=10)\n",
    "output3 = model(input3)\n",
    "\n",
    "output3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e570918",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f37ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.path_leye = GeneratorLocal()\n",
    "        self.path_reye = GeneratorLocal()\n",
    "        self.path_nose = GeneratorLocal()\n",
    "        self.path_mouth = GeneratorLocal()\n",
    "        \n",
    "        self.globalpath = GeneratorGlobal()\n",
    "        self.fuser = LocalFuser()\n",
    "        self.feature_predict = FeaturePredict(num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, img128, img64, img32, leye, reye, nose, mouth, noise):\n",
    "        \n",
    "        #Local Path\n",
    "        fake_leye, fake_leye_features = self.path_leye(leye)\n",
    "        fake_reye, fake_reye_features = self.path_reye(reye)\n",
    "        fake_nose, fake_nose_features = self.path_nose(nose)\n",
    "        fake_mouth, fake_mouth_features = self.path_mouth(mouth)\n",
    "        \n",
    "        #Merge Local Path\n",
    "        local_features = self.fuser(fake_leye_features, fake_reye_features, fake_nose_features, fake_mouth_features)\n",
    "        local_fake = self.fuser(fake_leye, fake_reye, fake_nose, fake_mouth)\n",
    "        local_GT = self.fuser(leye, reye, nose, mouth)\n",
    "        \n",
    "        #Global Path\n",
    "        fake_img128, fake_img64, fake_img32, fc2 = self.globalpath(img128, img64, img32, \n",
    "                                                                   local_fake, local_features, noise)\n",
    "        encoder_predict = self.feature_predict(fc2)\n",
    "        \n",
    "        return fake_img128, fake_img64, fake_img32, encoder_predict, \\\n",
    "                local_fake, fake_leye, fake_reye, fake_nose, fake_mouth, local_GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c00a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ae190f6",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dff4a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dim = [3, 64, 128, 256, 512]\n",
    "        \n",
    "        self.conv0 = nn.Sequential(\n",
    "                    conv_2d(dim[0], dim[1], ks=3, stride=2),\n",
    "                    batch_norm(dim[1]),\n",
    "                    lrelu())\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "                    conv_2d(dim[1], dim[2], ks=3, stride=2),\n",
    "                    batch_norm(dim[2]),\n",
    "                    lrelu())\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "                    conv_2d(dim[2], dim[3], ks=3, stride=2),\n",
    "                    batch_norm(dim[3]),\n",
    "                    lrelu())\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                    conv_2d(dim[3], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(ni=dim[4]))\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "                    conv_2d(dim[4], dim[4], ks=3, stride=2),\n",
    "                    batch_norm(dim[4]),\n",
    "                    lrelu(),\n",
    "                    ResBlock(ni=dim[4]))\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "                    conv_2d(dim[4], 1, ks=3, stride=1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f5af92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 1, 2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.randn(45, 3, 64, 64)\n",
    "model = Discriminator()\n",
    "output2 = model(input2)\n",
    "\n",
    "output2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff908b6",
   "metadata": {},
   "source": [
    "## Please ignore the code after this point. It was used to test the running of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4e5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b33952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28f4b5a2",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b91d81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 4, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4d = torch.empty(5, 4, 3)\n",
    "t4e = torch.empty(5, 4, 3)\n",
    "\n",
    "torch.stack([t4d, t4e], dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776da31",
   "metadata": {},
   "source": [
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e16a11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4d = torch.empty(2, 3)\n",
    "p1d = (1, -1)\n",
    "out = F.pad(t4d, p1d, \"constant\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "701294f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25770673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000e+00, 4.2039e-45, 0.0000e+00],\n",
       "        [5.0000e+00, 0.0000e+00, 1.5695e-43]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40672a9",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a57084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([5., 5.]),\n",
       "indices=tensor([0, 0]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc2a4eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out, 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2f5eb",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97b9536a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([104, 64, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(48, 64, 8, 8)\n",
    "input2 = torch.randn(56, 64, 8, 8)\n",
    "\n",
    "a = torch.cat((input1, input2), 0)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2ca47",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c0cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 5, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = 49\n",
    "a = torch.randn(aa, 5, 1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea7497",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "853956b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.LeakyReLU(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "829b7cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeakyReLU(negative_slope=0.1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00dcb0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9b905c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0709, -0.4352])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "870c45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = m(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f82fe4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0709, -0.0435])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027614a2",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bc8f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Conv2d(16, 33, 3, 2, 1)\n",
    "input2 = torch.randn(20, 16, 600, 50)\n",
    "output = m(input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d5f0758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 600, 50])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48b942e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 300, 25])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2df1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a49c1d",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "134adc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 300, 25])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = torch.randn(20, 16, 600, 50)\n",
    "a = conv_2d(16, 33, 3)\n",
    "a = a(input2)\n",
    "a.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
